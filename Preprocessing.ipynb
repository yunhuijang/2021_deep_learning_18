{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jjw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jjw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = './dataset/train_final.csv'\n",
    "output_data = './dataset/train_final_clean.csv'\n",
    "\n",
    "\n",
    "\n",
    "input_data = './dataset/eval_final_open.csv'\n",
    "output_data = './dataset/eval_final_clean.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Altogether , this is successful as a film , wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a cheap slasher flick , as the subject mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>... plays like somebody spliced random moments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>While the Resident Evil games may have set new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Too lazy to take advantage of its semi-humorou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Eric Schweig and Graham Greene both exude an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Huston nails both the glad-handing and the cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Not only are the special effects and narrative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>If you recognize Zeus -LRB- the dog from Snatc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>An enchanting spectacular for Potter fans anxi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           Sentence\n",
       "0   0  Altogether , this is successful as a film , wh...\n",
       "1   1  Not a cheap slasher flick , as the subject mat...\n",
       "2   2  ... plays like somebody spliced random moments...\n",
       "3   3  While the Resident Evil games may have set new...\n",
       "4   4  Too lazy to take advantage of its semi-humorou...\n",
       "5   5  Eric Schweig and Graham Greene both exude an a...\n",
       "6   6  Huston nails both the glad-handing and the cho...\n",
       "7   7  Not only are the special effects and narrative...\n",
       "8   8  If you recognize Zeus -LRB- the dog from Snatc...\n",
       "9   9  An enchanting spectacular for Potter fans anxi..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(input_data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for sentence in df['Sentence']:\n",
    "    try:\n",
    "        sentence = remove_punct(sentence, punct='`')\n",
    "        sentence = remove_punct(sentence, punct='-LRB-')\n",
    "        sentence = remove_punct(sentence, punct='-RRB-')\n",
    "        sentence = remove_punct(sentence, punct='is n\\'t', replace='is not')\n",
    "        sentence = remove_punct(sentence, punct='are n\\'t', replace='are not')\n",
    "        sentence = remove_punct(sentence, punct='was n\\'t', replace='was not')\n",
    "        sentence = remove_punct(sentence, punct='were n\\'t', replace='were not')\n",
    "        sentence = remove_punct(sentence, punct='ca n\\'t', replace='can not')\n",
    "        sentence = remove_punct(sentence, punct='could n\\'t', replace='could not')\n",
    "        sentence = remove_punct(sentence, punct='did n\\'t', replace='did not')\n",
    "        sentence = remove_punct(sentence, punct='do n\\'t', replace='do not')\n",
    "        sentence = remove_punct(sentence, punct='does n\\'t', replace='does not')\n",
    "        sentence = remove_punct(sentence, punct='have n\\'t', replace='have not')\n",
    "        \n",
    "        sentence = remove_punct(sentence, punct='\\\"')\n",
    "        sentence = remove_punct(sentence, punct='\\'\\'')\n",
    "        sentence = remove_punct(sentence, punct='\\'\\s')\n",
    "        sentence = remove_punct(sentence, punct='\\(')\n",
    "        sentence = remove_punct(sentence, punct='\\)')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "#         print(sentence)\n",
    "        pass\n",
    "    finally:\n",
    "        result.append(sentence)\n",
    "\n",
    "df['Clean'] = result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokencol = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = {'.', ',', '?', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '_', '-lrb-', '-rrb-', '`', '...', \"'\", ';', ':', '--', '``', }\n",
    "for Sentence in df['Sentence']:\n",
    "    result = []\n",
    "    token = word_tokenize(Sentence.lower())\n",
    "    for word in token:\n",
    "        if word not in stop_words and word not in punct:\n",
    "            result.append(word)\n",
    "    tokencol.append(result)\n",
    "\n",
    "df['Token'] = tokencol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-LRB- The film -RRB- tackles the topic of rela...</td>\n",
       "      <td>The film  tackles the topic of relationships ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lavishly , exhilaratingly tasteless .</td>\n",
       "      <td>Lavishly , exhilaratingly tasteless .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>It is also beautifully acted .</td>\n",
       "      <td>It is also beautifully acted .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>But , like Silence , it 's a movie that gets u...</td>\n",
       "      <td>But , like Silence , it 's a movie that gets u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>It 's been made with an innocent yet fervid co...</td>\n",
       "      <td>It 's been made with an innocent yet fervid co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Director David Jacobson gives Dahmer a conside...</td>\n",
       "      <td>Director David Jacobson gives Dahmer a conside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall , Cletis Tout is a winning comedy that...</td>\n",
       "      <td>Overall , Cletis Tout is a winning comedy that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>The movie is too impressed with its own solemn...</td>\n",
       "      <td>The movie is too impressed with its own solemn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>`` -LRB- Hopkins -RRB- does n't so much phone ...</td>\n",
       "      <td>Hopkins  does not so much phone in his perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Delirious fun .</td>\n",
       "      <td>Delirious fun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Too bland and fustily tasteful to be truly pru...</td>\n",
       "      <td>Too bland and fustily tasteful to be truly pru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>Ozpetek 's effort has the scope and shape of a...</td>\n",
       "      <td>Ozpetek 's effort has the scope and shape of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>As the Mediterranean sparkles , ` Swept Away '...</td>\n",
       "      <td>As the Mediterranean sparkles ,  Swept Away si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>Offers laughs and insight into one of the toug...</td>\n",
       "      <td>Offers laughs and insight into one of the toug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneven but a lot of fun .</td>\n",
       "      <td>Uneven but a lot of fun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>When compared to the usual , more somber festi...</td>\n",
       "      <td>When compared to the usual , more somber festi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>The sheer joy and pride they took in their wor...</td>\n",
       "      <td>The sheer joy and pride they took in their wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>A movie that seems motivated more by a desire ...</td>\n",
       "      <td>A movie that seems motivated more by a desire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>It does n't really know or care about the char...</td>\n",
       "      <td>It does not really know or care about the char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Distances you by throwing out so many red herr...</td>\n",
       "      <td>Distances you by throwing out so many red herr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>In his U.S. debut , Mr. Schnitzler proves hims...</td>\n",
       "      <td>In his U.S. debut , Mr. Schnitzler proves hims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>`` Home Movie '' is the film equivalent of a l...</td>\n",
       "      <td>Home Movie  is the film equivalent of a lovin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>It 's far from a frothy piece , and the charac...</td>\n",
       "      <td>It 's far from a frothy piece , and the charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>These characters become wearisome .</td>\n",
       "      <td>These characters become wearisome .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>George Lucas returns as a visionary with a tal...</td>\n",
       "      <td>George Lucas returns as a visionary with a tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>It 's the type of film about growing up that w...</td>\n",
       "      <td>It 's the type of film about growing up that w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>My Big Fat Greek Wedding is that rare animal k...</td>\n",
       "      <td>My Big Fat Greek Wedding is that rare animal k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>overburdened with complicated plotting and ban...</td>\n",
       "      <td>overburdened with complicated plotting and ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>Excellent performances from Jacqueline Bisset ...</td>\n",
       "      <td>Excellent performances from Jacqueline Bisset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>A live-wire film that never loses its ability ...</td>\n",
       "      <td>A live-wire film that never loses its ability ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Category                                           Sentence  \\\n",
       "0    0         3  -LRB- The film -RRB- tackles the topic of rela...   \n",
       "1    1         2              Lavishly , exhilaratingly tasteless .   \n",
       "2    2         4                     It is also beautifully acted .   \n",
       "3    3         1  But , like Silence , it 's a movie that gets u...   \n",
       "4    4         2  It 's been made with an innocent yet fervid co...   \n",
       "5    5         2  Director David Jacobson gives Dahmer a conside...   \n",
       "6    6         4  Overall , Cletis Tout is a winning comedy that...   \n",
       "7    7         1  The movie is too impressed with its own solemn...   \n",
       "8    8         1  `` -LRB- Hopkins -RRB- does n't so much phone ...   \n",
       "9    9         4                                    Delirious fun .   \n",
       "10  10         1  Too bland and fustily tasteful to be truly pru...   \n",
       "11  11         4  Ozpetek 's effort has the scope and shape of a...   \n",
       "12  12         1  As the Mediterranean sparkles , ` Swept Away '...   \n",
       "13  13         3  Offers laughs and insight into one of the toug...   \n",
       "14  14         3                          Uneven but a lot of fun .   \n",
       "15  15         4  When compared to the usual , more somber festi...   \n",
       "16  16         3  The sheer joy and pride they took in their wor...   \n",
       "17  17         2  A movie that seems motivated more by a desire ...   \n",
       "18  18         1  It does n't really know or care about the char...   \n",
       "19  19         0  Distances you by throwing out so many red herr...   \n",
       "20  20         4  In his U.S. debut , Mr. Schnitzler proves hims...   \n",
       "21  21         2  `` Home Movie '' is the film equivalent of a l...   \n",
       "22  22         3  It 's far from a frothy piece , and the charac...   \n",
       "23  23         1                These characters become wearisome .   \n",
       "24  24         3  George Lucas returns as a visionary with a tal...   \n",
       "25  25         3  It 's the type of film about growing up that w...   \n",
       "26  26         3  My Big Fat Greek Wedding is that rare animal k...   \n",
       "27  27         1  overburdened with complicated plotting and ban...   \n",
       "28  28         4  Excellent performances from Jacqueline Bisset ...   \n",
       "29  29         4  A live-wire film that never loses its ability ...   \n",
       "\n",
       "                                                Clean  \n",
       "0    The film  tackles the topic of relationships ...  \n",
       "1               Lavishly , exhilaratingly tasteless .  \n",
       "2                      It is also beautifully acted .  \n",
       "3   But , like Silence , it 's a movie that gets u...  \n",
       "4   It 's been made with an innocent yet fervid co...  \n",
       "5   Director David Jacobson gives Dahmer a conside...  \n",
       "6   Overall , Cletis Tout is a winning comedy that...  \n",
       "7   The movie is too impressed with its own solemn...  \n",
       "8     Hopkins  does not so much phone in his perfo...  \n",
       "9                                     Delirious fun .  \n",
       "10  Too bland and fustily tasteful to be truly pru...  \n",
       "11  Ozpetek 's effort has the scope and shape of a...  \n",
       "12  As the Mediterranean sparkles ,  Swept Away si...  \n",
       "13  Offers laughs and insight into one of the toug...  \n",
       "14                          Uneven but a lot of fun .  \n",
       "15  When compared to the usual , more somber festi...  \n",
       "16  The sheer joy and pride they took in their wor...  \n",
       "17  A movie that seems motivated more by a desire ...  \n",
       "18  It does not really know or care about the char...  \n",
       "19  Distances you by throwing out so many red herr...  \n",
       "20  In his U.S. debut , Mr. Schnitzler proves hims...  \n",
       "21   Home Movie  is the film equivalent of a lovin...  \n",
       "22  It 's far from a frothy piece , and the charac...  \n",
       "23                These characters become wearisome .  \n",
       "24  George Lucas returns as a visionary with a tal...  \n",
       "25  It 's the type of film about growing up that w...  \n",
       "26  My Big Fat Greek Wedding is that rare animal k...  \n",
       "27  overburdened with complicated plotting and ban...  \n",
       "28  Excellent performances from Jacqueline Bisset ...  \n",
       "29  A live-wire film that never loses its ability ...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['Sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "df['BERTToken']=tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Token</th>\n",
       "      <th>BERTToken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-LRB- The film -RRB- tackles the topic of rela...</td>\n",
       "      <td>The film  tackles the topic of relationships ...</td>\n",
       "      <td>[film, tackles, topic, relationships, straight...</td>\n",
       "      <td>[101, 1011, 1048, 15185, 1011, 1996, 2143, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lavishly , exhilaratingly tasteless .</td>\n",
       "      <td>Lavishly , exhilaratingly tasteless .</td>\n",
       "      <td>[lavishly, exhilaratingly, tasteless]</td>\n",
       "      <td>[101, 22689, 2135, 1010, 4654, 26415, 15172, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>It is also beautifully acted .</td>\n",
       "      <td>It is also beautifully acted .</td>\n",
       "      <td>[also, beautifully, acted]</td>\n",
       "      <td>[101, 2009, 2003, 2036, 17950, 6051, 1012, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>But , like Silence , it 's a movie that gets u...</td>\n",
       "      <td>But , like Silence , it 's a movie that gets u...</td>\n",
       "      <td>[like, silence, 's, movie, gets, skin]</td>\n",
       "      <td>[101, 2021, 1010, 2066, 4223, 1010, 2009, 1005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>It 's been made with an innocent yet fervid co...</td>\n",
       "      <td>It 's been made with an innocent yet fervid co...</td>\n",
       "      <td>['s, made, innocent, yet, fervid, conviction, ...</td>\n",
       "      <td>[101, 2009, 1005, 1055, 2042, 2081, 2007, 2019...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Category                                           Sentence  \\\n",
       "0   0         3  -LRB- The film -RRB- tackles the topic of rela...   \n",
       "1   1         2              Lavishly , exhilaratingly tasteless .   \n",
       "2   2         4                     It is also beautifully acted .   \n",
       "3   3         1  But , like Silence , it 's a movie that gets u...   \n",
       "4   4         2  It 's been made with an innocent yet fervid co...   \n",
       "\n",
       "                                               Clean  \\\n",
       "0   The film  tackles the topic of relationships ...   \n",
       "1              Lavishly , exhilaratingly tasteless .   \n",
       "2                     It is also beautifully acted .   \n",
       "3  But , like Silence , it 's a movie that gets u...   \n",
       "4  It 's been made with an innocent yet fervid co...   \n",
       "\n",
       "                                               Token  \\\n",
       "0  [film, tackles, topic, relationships, straight...   \n",
       "1              [lavishly, exhilaratingly, tasteless]   \n",
       "2                         [also, beautifully, acted]   \n",
       "3             [like, silence, 's, movie, gets, skin]   \n",
       "4  ['s, made, innocent, yet, fervid, conviction, ...   \n",
       "\n",
       "                                           BERTToken  \n",
       "0  [101, 1011, 1048, 15185, 1011, 1996, 2143, 101...  \n",
       "1  [101, 22689, 2135, 1010, 4654, 26415, 15172, 2...  \n",
       "2    [101, 2009, 2003, 2036, 17950, 6051, 1012, 102]  \n",
       "3  [101, 2021, 1010, 2066, 4223, 1010, 2009, 1005...  \n",
       "4  [101, 2009, 1005, 1055, 2042, 2081, 2007, 2019...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_data, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                                        130\n",
      "Sentence    While Undercover Brother is definitely one for...\n",
      "Clean       While Undercover Brother is definitely one for...\n",
      "Name: 130, dtype: object\n",
      "While Undercover Brother is definitely one for the masses , it 's also full of sharp , smart satire .\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[130])\n",
    "print(df.iloc[130,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 102, 999, 2102, 10439, 14753, 20624]\n",
      "[101, 102, 999, 2102, 10439, 14753, 20624]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(tokenizer.encode(df.iloc[8786,2])))\n",
    "print(sorted(tokenizer.encode(df.iloc[8786,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2188,\n",
       " 3185,\n",
       " 2003,\n",
       " 1037,\n",
       " 4086,\n",
       " 8813,\n",
       " 1998,\n",
       " 2242,\n",
       " 2092,\n",
       " 4276,\n",
       " 2115,\n",
       " 2051,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(df.iloc[8773,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@@ Hopkins -RRB- does n't so much phone in\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text, punct, replace=''):\n",
    "    return re.sub(punct+'+', replace, text)\n",
    "\n",
    "remove_punct(\"-LRB- Hopkins -RRB- does n't so much phone in\", '-LRB-', '@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(input_data, output_data):\n",
    "    df = pd.read_csv(input_data)\n",
    "    result = []\n",
    "    for sentence in df['Sentence']:\n",
    "        try:\n",
    "            sentence = remove_punct(sentence, punct='`')\n",
    "            sentence = remove_punct(sentence, punct='-LRB-')\n",
    "            sentence = remove_punct(sentence, punct='-RRB-')\n",
    "\n",
    "            sentence = remove_punct(sentence, punct='is n\\'t', replace='is not')\n",
    "            sentence = remove_punct(sentence, punct='are n\\'t', replace='are not')\n",
    "            sentence = remove_punct(sentence, punct='was n\\'t', replace='was not')\n",
    "            sentence = remove_punct(sentence, punct='were n\\'t', replace='were not')\n",
    "            sentence = remove_punct(sentence, punct='ca n\\'t', replace='can not')\n",
    "            sentence = remove_punct(sentence, punct='could n\\'t', replace='could not')\n",
    "            sentence = remove_punct(sentence, punct='did n\\'t', replace='did not')\n",
    "            sentence = remove_punct(sentence, punct='do n\\'t', replace='do not')\n",
    "            sentence = remove_punct(sentence, punct='does n\\'t', replace='does not')\n",
    "            sentence = remove_punct(sentence, punct='have n\\'t', replace='have not')\n",
    "\n",
    "            sentence = remove_punct(sentence, punct='\\\"')\n",
    "            sentence = remove_punct(sentence, punct='\\'\\'')\n",
    "            sentence = remove_punct(sentence, punct='\\'\\s')\n",
    "            sentence = remove_punct(sentence, punct='\\(')\n",
    "            sentence = remove_punct(sentence, punct='\\)')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "    #         print(e)\n",
    "    #         print(sentence)\n",
    "            pass\n",
    "        finally:\n",
    "            result.append(sentence)\n",
    "    \n",
    "    print(len(result))\n",
    "    del df['Sentence']\n",
    "    df['Sentence'] = result\n",
    "    df.to_csv(output_data, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11544\n",
      "4311\n"
     ]
    }
   ],
   "source": [
    "input_data = './dataset/train_final.csv'\n",
    "output_data = './dataset/train_final_clean.csv'\n",
    "data_cleaning(input_data, output_data)\n",
    "\n",
    "\n",
    "\n",
    "input_data = './dataset/eval_final_open.csv'\n",
    "output_data = './dataset/eval_final_clean.csv'\n",
    "data_cleaning(input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invqgrad",
   "language": "python",
   "name": "invqgrad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
